{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaparra/Virtual-Envs/malaria_pl/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely.ops import cascaded_union\n",
    "from shapely.geometry import MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Useful imports\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from constants import *\n",
    "from utils.publication_functions import beautify_data_column_name\n",
    "from sklearn.cluster import KMeans\n",
    "from flows.specific.custom_flow import CustomFlow\n",
    "\n",
    "# Data sources\n",
    "from data_sources.specific.coca import Coca\n",
    "from data_sources.specific.gold_stock_price import GoldStockPrice\n",
    "from data_sources.specific.malaria_cases import Malaria\n",
    "from data_sources.specific.mock_malaria_cases import MockMalaria\n",
    "from data_sources.specific.temperature_average import TemperatureAverage\n",
    "from data_sources.specific.temperature_max import TemperatureMax\n",
    "from data_sources.specific.temperature_min import TemperatureMin\n",
    "from data_sources.specific.temperature_average import TemperatureAverage\n",
    "from data_sources.specific.precipitation_average import PrecipitationAverage\n",
    "from data_sources.specific.precipitation_total import PrecipitationTotal\n",
    "from data_sources.specific.deforestation_average import DeforestationAverage\n",
    "from data_sources.specific.deforestation_total import DeforestationTotal\n",
    "from data_sources.specific.fb_mobility import FBMobility\n",
    "\n",
    "# Embedders\n",
    "from embedders.specific.identity_embedder import IdentityEmbbeder\n",
    "from embedders.specific.linear_regression_coefficient_embedder import LinearRegressionCoefficientEmbedder\n",
    "from embedders.specific.mobility_to_distance_embedder import MobilityToDistanceEmbeder\n",
    "from embedders.specific.mobility_to_similarity_embedder import MobilityToSimilarityEmbeder\n",
    "from embedders.specific.aggregation_embedder import AggregationEmbedder\n",
    "\n",
    "# Clusteres\n",
    "from clusterers.specific.identity_clusterer import IdentityClusterer\n",
    "from clusterers.specific.quantile_clusterer import QuantileClusterer\n",
    "from clusterers.specific.sklearn_vector_clusterer import SklearnVectorClusterer\n",
    "from clusterers.specific.two_tier_dbscan_clusterer import TwoTierDBSCANClusterer\n",
    "from clusterers.specific.similarity_community_clusterer import SimilarityCommunityClusterer\n",
    "\n",
    "# Geographies\n",
    "from geography.specific.colombian_municipalities import ColombianMunicipalities\n",
    "from geography.specific.colombia_grid import ColombianGrid\n",
    "from geography.specific.colombia_rivers import ColombianRivers\n",
    "from geography.general.geography_from_flow_output import GeographyFromFlowOutput\n",
    "from geography.specific.colombia_indg_com import ColombianIndgCom\n",
    "from geography.specific.colombia_indg_terr import ColombianIndgTerr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBD matrix data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DATE, ID_2, GEOMETRY, ID, PIPELINE_DATA_FOLDER, RAW, ID_1, SUB_ID, USUAL_PROJECTION, isTimeResolutionValid\n",
    "from data_sources.abstract.matrix_data_source import MatrixDataSource\n",
    "from utils.date_functions import get_period_representative_function\n",
    "\n",
    "\n",
    "# Constants\n",
    "SOURCE_ID = \"ibd\"\n",
    "NAME = \"Identity by Descent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBD(MatrixDataSource):\n",
    "    '''\n",
    "    Matrix Data Source\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ibd_threshold = 0.9\n",
    "\n",
    "    @property\n",
    "    def ID(self):\n",
    "        return SOURCE_ID\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return NAME\n",
    "\n",
    "    def set_ibd_threshold(self, ibd_threshold):\n",
    "        self.ibd_threshold = ibd_threshold\n",
    "\n",
    "\n",
    "\n",
    "    # Override\n",
    "    def createData(self, df_geo, time_resolution):\n",
    "\n",
    "        # Checks time resolution\n",
    "        isTimeResolutionValid(time_resolution)\n",
    "\n",
    "        # Data\n",
    "        data_path = os.path.join(PIPELINE_DATA_FOLDER, RAW, 'ibd', 'ibd_muni.csv')\n",
    "        muni_path = os.path.join(PIPELINE_DATA_FOLDER, RAW, 'geo', 'municipalities', 'municipalities.shp')\n",
    "\n",
    "        df = pd.read_csv(data_path, parse_dates=[\"date_1\", \"date_2\"], sep='\\t')\n",
    "        gdf_muni = gpd.read_file(muni_path)\n",
    "\n",
    "        # Takes to end of period\n",
    "        df[\"date_1\"] = df[\"date_1\"].apply(\n",
    "            get_period_representative_function(time_resolution))\n",
    "\n",
    "        df[\"date_2\"] = df[\"date_2\"].apply(\n",
    "            get_period_representative_function(time_resolution))\n",
    "\n",
    "        # Drop rows where time resolution doesn't match\n",
    "        df = df[df[\"date_1\"] == df[\"date_2\"]]\n",
    "        df.drop(columns=[\"date_2\"], inplace=True)\n",
    "        df.rename(columns={\"date_1\": \"date\"}, inplace=True)\n",
    "\n",
    "        # Group by date id1, id2, and date to get min\n",
    "        df = df.groupby([\"date\", \"ID_1\", \"ID_2\"]).min().reset_index()\n",
    "\n",
    "        # Adds geometry\n",
    "        # First ID_1\n",
    "        gdf_ibd_1 = gpd.GeoDataFrame(gdf_muni.merge(df, left_on=\"muni_id\", right_on=ID_1).dropna().drop(columns=[\"muni_id\"]), \n",
    "                geometry='geometry', crs=USUAL_PROJECTION)\n",
    "        gdf_ibd_1 = gpd.sjoin(gdf_ibd_1, df_geo[[ID, GEOMETRY]], how='left', predicate='contains')\n",
    "\n",
    "        # Then ID_2\n",
    "        gdf_ibd_2 = gpd.GeoDataFrame(gdf_muni.merge(df, left_on=\"muni_id\", right_on=ID_2).dropna().drop(columns=[\"muni_id\"]), \n",
    "                geometry='geometry', crs=USUAL_PROJECTION).dropna()                \n",
    "        gdf_ibd_2 = gpd.sjoin(gdf_ibd_2, df_geo[[ID, GEOMETRY]], how='left', predicate='contains').drop(['index_right', ID], axis=1)\n",
    "\n",
    "        # Merge gdf and merge geometries by union. Resulting geometry is the union of the corresponding polygons\n",
    "        gdf_ibd = gdf_ibd_1[[\"geometry\", \"date\", \"ID_1\", \"ID_2\"]].merge(gdf_ibd_2, on=[\"date\", \"ID_1\", \"ID_2\"])        \n",
    "\n",
    "        # Transform geomtry into a grouping\n",
    "        gdf_ibd[\"geometry\"] = gdf_ibd.apply(lambda x: gpd.GeoSeries([x[\"geometry_x\"], x[\"geometry_y\"]]).unary_union, axis=1)\n",
    "        gdf_ibd.drop(columns=[\"geometry_x\", \"geometry_y\"], inplace=True)\n",
    "        \n",
    "        gdf_ibd = gpd.GeoDataFrame(gdf_ibd, geometry='geometry')\n",
    "        return gdf_ibd\n",
    "\n",
    "    def createDataFromCachedSubGeography(self, time_resolution, sub_geography,\n",
    "                                         df_map):\n",
    "        # Checks time resolution\n",
    "        isTimeResolutionValid(time_resolution)\n",
    "\n",
    "        # Gets the data from the sub_geography\n",
    "        df = self.get_data(sub_geography, time_resolution)\n",
    "\n",
    "        # Maps the ids\n",
    "        # id 1\n",
    "        df.rename(columns={ID_1: SUB_ID}, inplace=True)\n",
    "        df = df.merge(df_map).rename(columns={ID: ID_1})\n",
    "        df.drop(SUB_ID, axis=1, inplace=True)\n",
    "        # Id 2\n",
    "        df.rename(columns={ID_2: SUB_ID}, inplace=True)\n",
    "        df = df.merge(df_map).rename(columns={ID: ID_2})\n",
    "        df.drop(SUB_ID, axis=1, inplace=True)\n",
    "\n",
    "        # Agglomerates\n",
    "        df_final = df.groupby([ID_1, ID_2, DATE]).sum().reset_index()\n",
    "\n",
    "        return (df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaparra/Virtual-Envs/malaria_pl/lib/python3.9/site-packages/pandas/core/dtypes/inference.py:383: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  iter(obj)  # Can iterate over it.\n",
      "/Users/andreaparra/Virtual-Envs/malaria_pl/lib/python3.9/site-packages/pandas/core/dtypes/inference.py:384: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  len(obj)  # Has a length associated with it.\n",
      "/Users/andreaparra/Virtual-Envs/malaria_pl/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1981: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  result[:] = values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ID_1</th>\n",
       "      <th>ID_2</th>\n",
       "      <th>ibd</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>76109</td>\n",
       "      <td>19318</td>\n",
       "      <td>0.04654</td>\n",
       "      <td>MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>76109</td>\n",
       "      <td>27001</td>\n",
       "      <td>0.26423</td>\n",
       "      <td>MULTIPOLYGON (((-77.23164 4.16706, -77.22345 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>76109</td>\n",
       "      <td>19318</td>\n",
       "      <td>0.11651</td>\n",
       "      <td>MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>76109</td>\n",
       "      <td>76109</td>\n",
       "      <td>0.99849</td>\n",
       "      <td>POLYGON ((-77.23164 4.16706, -77.22345 4.15799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>76109</td>\n",
       "      <td>19318</td>\n",
       "      <td>0.30528</td>\n",
       "      <td>MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   ID_1   ID_2      ibd  \\\n",
       "0 2020-01-31  76109  19318  0.04654   \n",
       "1 2020-01-31  76109  27001  0.26423   \n",
       "2 2020-02-29  76109  19318  0.11651   \n",
       "3 2020-02-29  76109  76109  0.99849   \n",
       "4 2020-03-31  76109  19318  0.30528   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...  \n",
       "1  MULTIPOLYGON (((-77.23164 4.16706, -77.22345 4...  \n",
       "2  MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...  \n",
       "3  POLYGON ((-77.23164 4.16706, -77.22345 4.15799...  \n",
       "4  MULTIPOLYGON (((-77.86901 2.27180, -77.86907 2...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muni_path = os.path.join(PIPELINE_DATA_FOLDER, RAW, 'geo', 'municipalities', 'municipalities.shp')\n",
    "gdf_muni = gpd.read_file(muni_path)\n",
    "gdf_muni.rename(columns={\"muni_id\": \"ID\"}, inplace=True)\n",
    "\n",
    "geography = ColombianMunicipalities()\n",
    "time_resolution = MONTH\n",
    "\n",
    "ds = IBD()\n",
    "gdf_ds = ds.createData(gdf_muni, time_resolution)\n",
    "gdf_ds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MultiPolygon([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaria_pl",
   "language": "python",
   "name": "malaria_pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
